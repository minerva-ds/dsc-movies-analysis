{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      tconst titleType                       primaryTitle  \\\n",
      "0  tt0013274     movie        Istoriya grazhdanskoy voyny   \n",
      "1  tt0070596     movie                  Socialist Realism   \n",
      "2  tt0077684     movie  Hist贸rias de Comb贸ios em Portugal   \n",
      "3  tt0096235     movie                        Taxi Killer   \n",
      "4  tt0097767     movie                     Loading Ludwig   \n",
      "\n",
      "                       originalTitle isAdult  startYear endYear  \\\n",
      "0        Istoriya grazhdanskoy voyny       0       2021      \\N   \n",
      "1             El realismo socialista       0       2023      \\N   \n",
      "2  Hist贸rias de Comb贸ios em Portugal       0       2022      \\N   \n",
      "3                        Taxi Killer       0       2022      \\N   \n",
      "4                     Loading Ludwig       0       2022      \\N   \n",
      "\n",
      "  runtimeMinutes              genres  averageRating  numVotes  \n",
      "0             94         Documentary            6.6      71.0  \n",
      "1             78               Drama            7.5      59.0  \n",
      "2             46         Documentary            NaN       NaN  \n",
      "3            106  Action,Crime,Drama            5.6      73.0  \n",
      "4             65                  \\N            7.0       6.0  \n",
      "Processed chunk 1/2800.0\n",
      "Processed chunk 2/2800.0\n",
      "Processed chunk 3/2800.0\n",
      "Processed chunk 4/2800.0\n",
      "Processed chunk 5/2800.0\n",
      "Processed chunk 6/2800.0\n",
      "Processed chunk 7/2800.0\n",
      "Processed chunk 8/2800.0\n",
      "Processed chunk 9/2800.0\n",
      "Processed chunk 10/2800.0\n",
      "Processed chunk 11/2800.0\n",
      "Processed chunk 12/2800.0\n",
      "Processed chunk 13/2800.0\n",
      "Processed chunk 14/2800.0\n",
      "Processed chunk 15/2800.0\n",
      "Processed chunk 16/2800.0\n",
      "Processed chunk 17/2800.0\n",
      "Processed chunk 18/2800.0\n",
      "Processed chunk 19/2800.0\n",
      "Processed chunk 20/2800.0\n",
      "Processed chunk 21/2800.0\n",
      "Processed chunk 22/2800.0\n",
      "Processed chunk 23/2800.0\n",
      "Processed chunk 24/2800.0\n",
      "Processed chunk 25/2800.0\n",
      "Processed chunk 26/2800.0\n",
      "Processed chunk 27/2800.0\n",
      "Processed chunk 28/2800.0\n",
      "Processed chunk 29/2800.0\n",
      "Processed chunk 30/2800.0\n",
      "Processed chunk 31/2800.0\n",
      "Processed chunk 32/2800.0\n",
      "Processed chunk 33/2800.0\n",
      "Processed chunk 34/2800.0\n",
      "Processed chunk 35/2800.0\n",
      "Processed chunk 36/2800.0\n",
      "Processed chunk 37/2800.0\n",
      "Processed chunk 38/2800.0\n",
      "Processed chunk 39/2800.0\n",
      "Processed chunk 40/2800.0\n",
      "Processed chunk 41/2800.0\n",
      "Processed chunk 42/2800.0\n",
      "Processed chunk 43/2800.0\n",
      "Processed chunk 44/2800.0\n",
      "Processed chunk 45/2800.0\n",
      "Processed chunk 46/2800.0\n",
      "Processed chunk 47/2800.0\n",
      "Processed chunk 48/2800.0\n",
      "Processed chunk 49/2800.0\n",
      "Processed chunk 50/2800.0\n",
      "Processed chunk 51/2800.0\n",
      "Processed chunk 52/2800.0\n",
      "Processed chunk 53/2800.0\n",
      "Processed chunk 54/2800.0\n",
      "Processed chunk 55/2800.0\n",
      "Error fetching data for IMDb IDs ['tt10934208', 'tt10934398', 'tt10934734', 'tt10934920', 'tt10935152', 'tt10935540', 'tt10935560', 'tt10935956', 'tt10936700', 'tt10936934', 'tt10937366', 'tt10937496', 'tt10937932', 'tt10938608', 'tt10938882', 'tt10939474', 'tt10939740', 'tt10939802', 'tt10940162', 'tt10940376', 'tt10940662', 'tt10940736', 'tt10940890', 'tt10941992', 'tt10942166'] with info genres: 502 Server Error: Bad Gateway for url: https://moviesdatabase.p.rapidapi.com/titles/x/titles-by-ids?idsList=tt10934208%2Ctt10934398%2Ctt10934734%2Ctt10934920%2Ctt10935152%2Ctt10935540%2Ctt10935560%2Ctt10935956%2Ctt10936700%2Ctt10936934%2Ctt10937366%2Ctt10937496%2Ctt10937932%2Ctt10938608%2Ctt10938882%2Ctt10939474%2Ctt10939740%2Ctt10939802%2Ctt10940162%2Ctt10940376%2Ctt10940662%2Ctt10940736%2Ctt10940890%2Ctt10941992%2Ctt10942166&info=genres\n",
      "Response status code: 502\n",
      "Response text: {\"messages\":\"The API is unreachable, please contact the API provider\", \"info\": \"Your Client (working) ---> Gateway (working) ---> API (not working)\"}\n",
      "No valid results for info: genres\n",
      "None\n",
      "Processed chunk 56/2800.0\n",
      "Processed chunk 57/2800.0\n",
      "Processed chunk 58/2800.0\n",
      "Processed chunk 59/2800.0\n",
      "Processed chunk 60/2800.0\n",
      "Processed chunk 61/2800.0\n",
      "Processed chunk 62/2800.0\n",
      "Processed chunk 63/2800.0\n",
      "Processed chunk 64/2800.0\n",
      "Processed chunk 65/2800.0\n",
      "Processed chunk 66/2800.0\n",
      "Processed chunk 67/2800.0\n",
      "Error fetching data for IMDb IDs ['tt11101808', 'tt11102198', 'tt11102262', 'tt11102314', 'tt11102856', 'tt11105376', 'tt11105790', 'tt11106034', 'tt11106626', 'tt11107528', 'tt11107884', 'tt11110938', 'tt11112126', 'tt11112532', 'tt11112696', 'tt11112784', 'tt11112808', 'tt11114880', 'tt11115272', 'tt11115706', 'tt11115882', 'tt11116374', 'tt11116642', 'tt11116912', 'tt11120378'] with info awards: 502 Server Error: Bad Gateway for url: https://moviesdatabase.p.rapidapi.com/titles/x/titles-by-ids?idsList=tt11101808%2Ctt11102198%2Ctt11102262%2Ctt11102314%2Ctt11102856%2Ctt11105376%2Ctt11105790%2Ctt11106034%2Ctt11106626%2Ctt11107528%2Ctt11107884%2Ctt11110938%2Ctt11112126%2Ctt11112532%2Ctt11112696%2Ctt11112784%2Ctt11112808%2Ctt11114880%2Ctt11115272%2Ctt11115706%2Ctt11115882%2Ctt11116374%2Ctt11116642%2Ctt11116912%2Ctt11120378&info=awards\n",
      "Response status code: 502\n",
      "Response text: {\"messages\":\"The API is unreachable, please contact the API provider\", \"info\": \"Your Client (working) ---> Gateway (working) ---> API (not working)\"}\n",
      "No valid results for info: awards\n",
      "None\n",
      "Processed chunk 68/2800.0\n",
      "Processed chunk 69/2800.0\n",
      "Processed chunk 70/2800.0\n",
      "Processed chunk 71/2800.0\n",
      "Processed chunk 72/2800.0\n",
      "Processed chunk 73/2800.0\n",
      "Processed chunk 74/2800.0\n",
      "Processed chunk 75/2800.0\n",
      "Processed chunk 76/2800.0\n",
      "Processed chunk 77/2800.0\n",
      "Processed chunk 78/2800.0\n",
      "Processed chunk 79/2800.0\n",
      "Processed chunk 80/2800.0\n",
      "Processed chunk 81/2800.0\n",
      "Processed chunk 82/2800.0\n",
      "Processed chunk 83/2800.0\n",
      "Processed chunk 84/2800.0\n",
      "Processed chunk 85/2800.0\n",
      "Processed chunk 86/2800.0\n",
      "Processed chunk 87/2800.0\n",
      "Processed chunk 88/2800.0\n",
      "Processed chunk 89/2800.0\n",
      "Processed chunk 90/2800.0\n",
      "Processed chunk 91/2800.0\n",
      "Processed chunk 92/2800.0\n",
      "Processed chunk 93/2800.0\n",
      "Processed chunk 94/2800.0\n",
      "Processed chunk 95/2800.0\n",
      "Processed chunk 96/2800.0\n",
      "Processed chunk 97/2800.0\n",
      "Processed chunk 98/2800.0\n",
      "Processed chunk 99/2800.0\n",
      "Processed chunk 100/2800.0\n",
      "Processed chunk 101/2800.0\n",
      "Processed chunk 102/2800.0\n",
      "Processed chunk 103/2800.0\n",
      "Processed chunk 104/2800.0\n",
      "Processed chunk 105/2800.0\n",
      "Processed chunk 106/2800.0\n",
      "Processed chunk 107/2800.0\n",
      "Processed chunk 108/2800.0\n",
      "Processed chunk 109/2800.0\n",
      "Processed chunk 110/2800.0\n",
      "Processed chunk 111/2800.0\n",
      "Processed chunk 112/2800.0\n",
      "Processed chunk 113/2800.0\n",
      "Processed chunk 114/2800.0\n",
      "Processed chunk 115/2800.0\n",
      "Processed chunk 116/2800.0\n",
      "Processed chunk 117/2800.0\n",
      "Processed chunk 118/2800.0\n",
      "Processed chunk 119/2800.0\n",
      "Processed chunk 120/2800.0\n",
      "Processed chunk 121/2800.0\n",
      "Processed chunk 122/2800.0\n",
      "Processed chunk 123/2800.0\n",
      "Processed chunk 124/2800.0\n",
      "Processed chunk 125/2800.0\n",
      "Processed chunk 126/2800.0\n",
      "Processed chunk 127/2800.0\n",
      "Processed chunk 128/2800.0\n",
      "Processed chunk 129/2800.0\n",
      "Processed chunk 130/2800.0\n",
      "Processed chunk 131/2800.0\n",
      "Processed chunk 132/2800.0\n",
      "Processed chunk 133/2800.0\n",
      "Processed chunk 134/2800.0\n",
      "Processed chunk 135/2800.0\n",
      "Processed chunk 136/2800.0\n",
      "Processed chunk 137/2800.0\n",
      "Processed chunk 138/2800.0\n",
      "Processed chunk 139/2800.0\n",
      "Processed chunk 140/2800.0\n",
      "Processed chunk 141/2800.0\n",
      "Processed chunk 142/2800.0\n",
      "Processed chunk 143/2800.0\n",
      "Processed chunk 144/2800.0\n",
      "Processed chunk 145/2800.0\n",
      "Processed chunk 146/2800.0\n",
      "Processed chunk 147/2800.0\n",
      "Processed chunk 148/2800.0\n",
      "Processed chunk 149/2800.0\n",
      "Processed chunk 150/2800.0\n",
      "Processed chunk 151/2800.0\n",
      "Processed chunk 152/2800.0\n",
      "Processed chunk 153/2800.0\n",
      "Processed chunk 154/2800.0\n",
      "Processed chunk 155/2800.0\n",
      "Processed chunk 156/2800.0\n",
      "Processed chunk 157/2800.0\n",
      "Processed chunk 158/2800.0\n",
      "Processed chunk 159/2800.0\n",
      "Processed chunk 160/2800.0\n",
      "Processed chunk 161/2800.0\n",
      "Processed chunk 162/2800.0\n",
      "Processed chunk 163/2800.0\n",
      "Processed chunk 164/2800.0\n",
      "Processed chunk 165/2800.0\n",
      "Processed chunk 166/2800.0\n",
      "Processed chunk 167/2800.0\n",
      "Processed chunk 168/2800.0\n",
      "Processed chunk 169/2800.0\n",
      "Processed chunk 170/2800.0\n",
      "Processed chunk 171/2800.0\n",
      "Processed chunk 172/2800.0\n",
      "Processed chunk 173/2800.0\n",
      "Processed chunk 174/2800.0\n",
      "Processed chunk 175/2800.0\n",
      "Processed chunk 176/2800.0\n",
      "Processed chunk 177/2800.0\n",
      "Processed chunk 178/2800.0\n",
      "Processed chunk 179/2800.0\n",
      "Processed chunk 180/2800.0\n",
      "Processed chunk 181/2800.0\n",
      "Processed chunk 182/2800.0\n",
      "Processed chunk 183/2800.0\n",
      "Processed chunk 184/2800.0\n",
      "Processed chunk 185/2800.0\n",
      "Processed chunk 186/2800.0\n",
      "Processed chunk 187/2800.0\n",
      "Processed chunk 188/2800.0\n",
      "Processed chunk 189/2800.0\n",
      "Processed chunk 190/2800.0\n",
      "Processed chunk 191/2800.0\n",
      "Processed chunk 192/2800.0\n",
      "Processed chunk 193/2800.0\n",
      "Processed chunk 194/2800.0\n",
      "Processed chunk 195/2800.0\n",
      "Processed chunk 196/2800.0\n",
      "Processed chunk 197/2800.0\n",
      "Processed chunk 198/2800.0\n",
      "Processed chunk 199/2800.0\n",
      "Processed chunk 200/2800.0\n",
      "Processed chunk 201/2800.0\n",
      "Processed chunk 202/2800.0\n",
      "Processed chunk 203/2800.0\n",
      "Processed chunk 204/2800.0\n",
      "Processed chunk 205/2800.0\n",
      "Processed chunk 206/2800.0\n",
      "Processed chunk 207/2800.0\n",
      "Processed chunk 208/2800.0\n",
      "Processed chunk 209/2800.0\n",
      "Processed chunk 210/2800.0\n",
      "Processed chunk 211/2800.0\n",
      "Processed chunk 212/2800.0\n",
      "Processed chunk 213/2800.0\n",
      "Processed chunk 214/2800.0\n",
      "Processed chunk 215/2800.0\n",
      "Processed chunk 216/2800.0\n",
      "Processed chunk 217/2800.0\n",
      "Processed chunk 218/2800.0\n",
      "Processed chunk 219/2800.0\n",
      "Processed chunk 220/2800.0\n",
      "Processed chunk 221/2800.0\n",
      "Processed chunk 222/2800.0\n",
      "Processed chunk 223/2800.0\n",
      "Processed chunk 224/2800.0\n",
      "Processed chunk 225/2800.0\n",
      "Processed chunk 226/2800.0\n",
      "Processed chunk 227/2800.0\n",
      "Processed chunk 228/2800.0\n",
      "Processed chunk 229/2800.0\n",
      "Processed chunk 230/2800.0\n",
      "Processed chunk 231/2800.0\n",
      "Processed chunk 232/2800.0\n",
      "Processed chunk 233/2800.0\n",
      "Processed chunk 234/2800.0\n",
      "Processed chunk 235/2800.0\n",
      "Processed chunk 236/2800.0\n",
      "Processed chunk 237/2800.0\n",
      "Processed chunk 238/2800.0\n",
      "Processed chunk 239/2800.0\n",
      "Processed chunk 240/2800.0\n",
      "Processed chunk 241/2800.0\n",
      "Processed chunk 242/2800.0\n",
      "Processed chunk 243/2800.0\n",
      "Processed chunk 244/2800.0\n",
      "Processed chunk 245/2800.0\n",
      "Processed chunk 246/2800.0\n",
      "Processed chunk 247/2800.0\n",
      "Processed chunk 248/2800.0\n",
      "Processed chunk 249/2800.0\n",
      "Processed chunk 250/2800.0\n",
      "Processed chunk 251/2800.0\n",
      "Processed chunk 252/2800.0\n",
      "Processed chunk 253/2800.0\n",
      "Processed chunk 254/2800.0\n",
      "Processed chunk 255/2800.0\n",
      "Processed chunk 256/2800.0\n",
      "Processed chunk 257/2800.0\n",
      "Processed chunk 258/2800.0\n",
      "Processed chunk 259/2800.0\n",
      "Processed chunk 260/2800.0\n",
      "Processed chunk 261/2800.0\n",
      "Processed chunk 262/2800.0\n",
      "Processed chunk 263/2800.0\n",
      "Processed chunk 264/2800.0\n",
      "Processed chunk 265/2800.0\n",
      "Processed chunk 266/2800.0\n",
      "Processed chunk 267/2800.0\n",
      "Processed chunk 268/2800.0\n",
      "Processed chunk 269/2800.0\n",
      "Processed chunk 270/2800.0\n",
      "Processed chunk 271/2800.0\n",
      "Processed chunk 272/2800.0\n",
      "Processed chunk 273/2800.0\n",
      "Processed chunk 274/2800.0\n",
      "Processed chunk 275/2800.0\n",
      "Processed chunk 276/2800.0\n",
      "Processed chunk 277/2800.0\n",
      "Processed chunk 278/2800.0\n",
      "Processed chunk 279/2800.0\n",
      "Processed chunk 280/2800.0\n",
      "Processed chunk 281/2800.0\n",
      "Processed chunk 282/2800.0\n",
      "Processed chunk 283/2800.0\n",
      "Processed chunk 284/2800.0\n",
      "Processed chunk 285/2800.0\n",
      "Processed chunk 286/2800.0\n",
      "Processed chunk 287/2800.0\n",
      "Processed chunk 288/2800.0\n",
      "Processed chunk 289/2800.0\n",
      "Processed chunk 290/2800.0\n",
      "Processed chunk 291/2800.0\n",
      "Processed chunk 292/2800.0\n",
      "Processed chunk 293/2800.0\n",
      "Processed chunk 294/2800.0\n",
      "Processed chunk 295/2800.0\n",
      "Processed chunk 296/2800.0\n",
      "Processed chunk 297/2800.0\n",
      "Processed chunk 298/2800.0\n",
      "Processed chunk 299/2800.0\n",
      "Processed chunk 300/2800.0\n",
      "Processed chunk 301/2800.0\n",
      "Processed chunk 302/2800.0\n",
      "Processed chunk 303/2800.0\n",
      "Processed chunk 304/2800.0\n",
      "Processed chunk 305/2800.0\n",
      "Processed chunk 306/2800.0\n",
      "Error fetching data for IMDb IDs ['tt13696316', 'tt13696424', 'tt13696480', 'tt13696668', 'tt13696746', 'tt13697240', 'tt13698116', 'tt13698406', 'tt13698742', 'tt13698928', 'tt13698942', 'tt13699132', 'tt13699300', 'tt13699684', 'tt13701404', 'tt13701506', 'tt13701656', 'tt13701696', 'tt13701802', 'tt13701810', 'tt13701918', 'tt13701938', 'tt13701962', 'tt13702196', 'tt13702796'] with info genres: 502 Server Error: Bad Gateway for url: https://moviesdatabase.p.rapidapi.com/titles/x/titles-by-ids?idsList=tt13696316%2Ctt13696424%2Ctt13696480%2Ctt13696668%2Ctt13696746%2Ctt13697240%2Ctt13698116%2Ctt13698406%2Ctt13698742%2Ctt13698928%2Ctt13698942%2Ctt13699132%2Ctt13699300%2Ctt13699684%2Ctt13701404%2Ctt13701506%2Ctt13701656%2Ctt13701696%2Ctt13701802%2Ctt13701810%2Ctt13701918%2Ctt13701938%2Ctt13701962%2Ctt13702196%2Ctt13702796&info=genres\n",
      "Response status code: 502\n",
      "Response text: {\"messages\":\"The API is unreachable, please contact the API provider\", \"info\": \"Your Client (working) ---> Gateway (working) ---> API (not working)\"}\n",
      "No valid results for info: genres\n",
      "None\n",
      "Processed chunk 307/2800.0\n",
      "Processed chunk 308/2800.0\n",
      "Processed chunk 309/2800.0\n",
      "Processed chunk 310/2800.0\n",
      "Processed chunk 311/2800.0\n",
      "Processed chunk 312/2800.0\n",
      "Processed chunk 313/2800.0\n",
      "Processed chunk 314/2800.0\n",
      "Processed chunk 315/2800.0\n",
      "Processed chunk 316/2800.0\n",
      "Processed chunk 317/2800.0\n",
      "Processed chunk 318/2800.0\n",
      "Processed chunk 319/2800.0\n",
      "Processed chunk 320/2800.0\n",
      "Processed chunk 321/2800.0\n",
      "Processed chunk 322/2800.0\n",
      "Processed chunk 323/2800.0\n",
      "Processed chunk 324/2800.0\n",
      "Processed chunk 325/2800.0\n",
      "Processed chunk 326/2800.0\n",
      "Processed chunk 327/2800.0\n",
      "Processed chunk 328/2800.0\n",
      "Processed chunk 329/2800.0\n",
      "Processed chunk 330/2800.0\n",
      "Processed chunk 331/2800.0\n",
      "Processed chunk 332/2800.0\n",
      "Processed chunk 333/2800.0\n",
      "Processed chunk 334/2800.0\n",
      "Processed chunk 335/2800.0\n",
      "Processed chunk 336/2800.0\n",
      "Processed chunk 337/2800.0\n",
      "Processed chunk 338/2800.0\n",
      "Processed chunk 339/2800.0\n",
      "Processed chunk 340/2800.0\n",
      "Processed chunk 341/2800.0\n",
      "Processed chunk 342/2800.0\n",
      "Processed chunk 343/2800.0\n",
      "Processed chunk 344/2800.0\n",
      "Processed chunk 345/2800.0\n",
      "Processed chunk 346/2800.0\n",
      "Processed chunk 347/2800.0\n",
      "Processed chunk 348/2800.0\n",
      "Processed chunk 349/2800.0\n",
      "Processed chunk 350/2800.0\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load the DataFrame from the pickle file\n",
    "merged_df = pd.read_pickle('last_three_years_movies_with_ratings.pkl')\n",
    "\n",
    "# Display the first few rows to verify the DataFrame\n",
    "print(merged_df.head())\n",
    "\n",
    "# Read the API key from the file\n",
    "with open('rapidapi.key', 'r') as file:\n",
    "    api_key = file.read().strip()\n",
    "\n",
    "# Now use the api_key variable in your code\n",
    "print(api_key)  # Just to verify it's reading correctly\n",
    "\n",
    "base_url = 'https://moviesdatabase.p.rapidapi.com/titles/x/titles-by-ids'\n",
    "\n",
    "# Define headers\n",
    "headers = {\n",
    "    'x-rapidapi-key': api_key,\n",
    "    'x-rapidapi-host': 'moviesdatabase.p.rapidapi.com'\n",
    "}\n",
    "\n",
    "# Utility function to get nested dictionary values\n",
    "def get_nested(data, keys, default=None):\n",
    "    for key in keys:\n",
    "        try:\n",
    "            data = data[key]\n",
    "        except (KeyError, TypeError):\n",
    "            return default\n",
    "    return data\n",
    "\n",
    "# Function to fetch detailed movie data for multiple IMDb IDs\n",
    "def fetch_bulk_movie_details(imdb_ids, info):\n",
    "    url = base_url\n",
    "    payload = {\n",
    "        \"idsList\": \",\".join(imdb_ids),\n",
    "        \"info\": info\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, params=payload)\n",
    "        response.raise_for_status()  # Raise HTTPError for bad responses\n",
    "        return response.json(), imdb_ids  # Return response JSON and the IMDb IDs\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching data for IMDb IDs {imdb_ids} with info {info}: {e}\")\n",
    "        print(f\"Response status code: {response.status_code}\")\n",
    "        print(f\"Response text: {response.text}\")\n",
    "        return None, imdb_ids\n",
    "\n",
    "# Function to merge data from multiple info parameters\n",
    "def merge_movie_details(imdb_ids, infos):\n",
    "    all_details = {imdb_id: {} for imdb_id in imdb_ids}\n",
    "    \n",
    "    for info in infos:\n",
    "        details, ids = fetch_bulk_movie_details(imdb_ids, info)\n",
    "        if details and 'results' in details:\n",
    "            if isinstance(details['results'], list):\n",
    "                for idx, result in enumerate(details['results']):\n",
    "                    imdb_id = ids[idx]\n",
    "                    if imdb_id in all_details:\n",
    "                        all_details[imdb_id].update(result)\n",
    "            else:\n",
    "                print(f\"No valid results for info: {info}\")\n",
    "        else:\n",
    "            print(f\"No valid results for info: {info}\")\n",
    "            print(details)  # Display details only if it's not something we can iterate\n",
    "\n",
    "    return all_details\n",
    "\n",
    "# Function to flatten nested JSON\n",
    "def flatten_json(json_data):\n",
    "    out = {}\n",
    "\n",
    "    def flatten(x, name=''):\n",
    "        if isinstance(x, dict):\n",
    "            for a in x:\n",
    "                flatten(x[a], name + a + '_')\n",
    "        elif isinstance(x, list):\n",
    "            for i, a in enumerate(x):\n",
    "                flatten(a, name + str(i) + '_')\n",
    "        else:\n",
    "            out[name[:-1]] = x\n",
    "\n",
    "    flatten(json_data)\n",
    "    return out\n",
    "\n",
    "# Function to split a list into chunks\n",
    "def chunk_list(data, chunk_size):\n",
    "    for i in range(0, len(data), chunk_size):\n",
    "        yield data[i:i + chunk_size]\n",
    "\n",
    "# Function to fetch and process data in bulk\n",
    "def fetch_and_process_data(imdb_ids, chunk_size, num_chunks=1, progress_pickle='in_progress.pkl'):\n",
    "    # Define the valid info parameters we want to fetch\n",
    "    infos = [\"base_info\", \"genres\", \"revenue_budget\", \"releaseDate\", \"rating\", \"awards\"]\n",
    "    \n",
    "    # List to hold detailed movie data\n",
    "    movie_details_list = []\n",
    "\n",
    "    # Load progress if the pickle file exists\n",
    "    if os.path.exists(progress_pickle):\n",
    "        with open(progress_pickle, 'rb') as f:\n",
    "            processed_chunks = pd.read_pickle(f)\n",
    "            movie_details_list.extend(processed_chunks)\n",
    "        print(f\"Resuming from {len(processed_chunks)} processed chunks.\")\n",
    "    else:\n",
    "        processed_chunks = []\n",
    "\n",
    "    # Fetch data for each chunk of IMDb IDs\n",
    "    for chunk_count, chunk in enumerate(chunk_list(imdb_ids, chunk_size)):\n",
    "        if chunk_count < len(processed_chunks):\n",
    "            continue  # Skip already processed chunks\n",
    "        if chunk_count >= num_chunks:\n",
    "            break\n",
    "        details = merge_movie_details(chunk, infos)\n",
    "        if details:\n",
    "            for imdb_id, detail in details.items():\n",
    "                detail['imdb_id'] = imdb_id  # Add the IMDb ID back to the detail\n",
    "            flattened_data = [flatten_json(value) for value in details.values()]\n",
    "            movie_details_list.extend(flattened_data)\n",
    "\n",
    "            # Save progress to the pickle file\n",
    "            with open(progress_pickle, 'wb') as f:\n",
    "                pd.to_pickle(movie_details_list, f)\n",
    "        print(f\"Processed chunk {chunk_count + 1}/{num_chunks}\")\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    movie_details_df = pd.DataFrame(movie_details_list)\n",
    "\n",
    "    return movie_details_df\n",
    "\n",
    "# Get IMDb IDs from the DataFrame\n",
    "imdb_ids = merged_df['tconst'].tolist()\n",
    "\n",
    "# Set the chunk size and number of chunks (e.g., 25 IDs per request, and 10 chunks)\n",
    "chunk_size = 25  # Adjusted to 25 based on API limits\n",
    "num_chunks = 70000/25 \n",
    "\n",
    "# Fetch and process data in bulk\n",
    "movie_details_df = fetch_and_process_data(imdb_ids, chunk_size, num_chunks)\n",
    "\n",
    "# Ensure 'imdb_id' exists in the movie_details_df before merging\n",
    "if 'imdb_id' in movie_details_df.columns:\n",
    "    # Merge the new movie details DataFrame with the original DataFrame\n",
    "    final_df = merged_df.merge(movie_details_df, left_on='tconst', right_on='imdb_id', how='left')\n",
    "else:\n",
    "    final_df = merged_df\n",
    "\n",
    "# Display the merged DataFrame\n",
    "print(final_df.head())\n",
    "\n",
    "# Save the final DataFrame to a new pickle file\n",
    "final_pickle = 'last_three_years_movies_with_detailed_data.pkl'\n",
    "final_df.to_pickle(final_pickle)\n",
    "\n",
    "# Remove the in-progress pickle file upon successful completion\n",
    "if os.path.exists('in_progress.pkl'):\n",
    "    os.remove('in_progress.pkl')\n",
    "\n",
    "print(f\"Data saved to {final_pickle}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tconst': 'tt0013274',\n",
       " 'titleType': 'movie',\n",
       " 'primaryTitle': 'Istoriya grazhdanskoy voyny',\n",
       " 'originalTitle': 'Istoriya grazhdanskoy voyny',\n",
       " 'isAdult': 0,\n",
       " 'startYear': 2021,\n",
       " 'endYear': '\\\\N',\n",
       " 'runtimeMinutes': '94',\n",
       " 'genres_x': 'Documentary',\n",
       " 'averageRating': 6.6,\n",
       " 'numVotes': 71.0,\n",
       " '_id': '61e58022d735dff3f9412891',\n",
       " 'id': 'tt0013274',\n",
       " 'ratingsSummary_aggregateRating': 6.6,\n",
       " 'ratingsSummary_voteCount': 71.0,\n",
       " 'ratingsSummary___typename': 'RatingsSummary',\n",
       " 'episodes': None,\n",
       " 'primaryImage_id': 'rm3867208705',\n",
       " 'primaryImage_width': 2868.0,\n",
       " 'primaryImage_height': 2154.0,\n",
       " 'primaryImage_url': 'https://m.media-amazon.com/images/M/MV5BMjBhZjQ2NGMtZjUwNC00OTJmLWI0ODctYmI5OTc5ZGM5ZTY5XkEyXkFqcGdeQXVyMTQxMDQ2MDEz._V1_.jpg',\n",
       " 'primaryImage_caption_plainText': 'Istoriya grazhdanskoy voyny (1922)',\n",
       " 'primaryImage_caption___typename': 'Markdown',\n",
       " 'primaryImage___typename': 'Image',\n",
       " 'titleType_text': 'Movie',\n",
       " 'titleType_id': 'movie',\n",
       " 'titleType_isSeries': False,\n",
       " 'titleType_isEpisode': False,\n",
       " 'titleType___typename': 'TitleType',\n",
       " 'genres_genres_0_text': 'Documentary',\n",
       " 'genres_genres_0_id': 'Documentary',\n",
       " 'genres_genres_0___typename': 'Genre',\n",
       " 'genres___typename': 'Genres',\n",
       " 'titleText_text': 'Istoriya grazhdanskoy voyny',\n",
       " 'titleText___typename': 'TitleText',\n",
       " 'originalTitleText_text': 'Istoriya grazhdanskoy voyny',\n",
       " 'originalTitleText___typename': 'TitleText',\n",
       " 'releaseYear_year': 1922.0,\n",
       " 'releaseYear_endYear': nan,\n",
       " 'releaseYear___typename': 'YearRange',\n",
       " 'releaseDate_day': 20.0,\n",
       " 'releaseDate_month': 11.0,\n",
       " 'releaseDate_year': 2021.0,\n",
       " 'releaseDate___typename': 'ReleaseDate',\n",
       " 'runtime_seconds': 7980.0,\n",
       " 'runtime___typename': 'Runtime',\n",
       " 'series': None,\n",
       " 'meterRanking': nan,\n",
       " 'plot': nan,\n",
       " 'productionBudget': nan,\n",
       " 'lifetimeGross': nan,\n",
       " 'openingWeekendGross': nan,\n",
       " 'worldwideGross': nan,\n",
       " 'wins_total': 0.0,\n",
       " 'wins___typename': 'AwardNominationConnection',\n",
       " 'nominations_total': 0.0,\n",
       " 'nominations___typename': 'AwardNominationConnection',\n",
       " 'prestigiousAwardSummary': None,\n",
       " 'imdb_id': 'tt0013274',\n",
       " 'plot_plotText_plainText': nan,\n",
       " 'plot_plotText___typename': nan,\n",
       " 'plot_language_id': nan,\n",
       " 'plot_language___typename': nan,\n",
       " 'plot___typename': nan,\n",
       " 'primaryImage': nan,\n",
       " 'genres_genres_1_text': nan,\n",
       " 'genres_genres_1_id': nan,\n",
       " 'genres_genres_1___typename': nan,\n",
       " 'releaseDate': nan,\n",
       " 'genres_genres_2_text': nan,\n",
       " 'genres_genres_2_id': nan,\n",
       " 'genres_genres_2___typename': nan,\n",
       " 'runtime': nan,\n",
       " 'genres_y': nan,\n",
       " 'releaseYear': nan,\n",
       " 'genres_genres_3_text': nan,\n",
       " 'genres_genres_3_id': nan,\n",
       " 'genres_genres_3___typename': nan,\n",
       " 'genres_genres_4_text': nan,\n",
       " 'genres_genres_4_id': nan,\n",
       " 'genres_genres_4___typename': nan,\n",
       " 'meterRanking_currentRank': nan,\n",
       " 'meterRanking_rankChange_changeDirection': nan,\n",
       " 'meterRanking_rankChange_difference': nan,\n",
       " 'meterRanking_rankChange___typename': nan,\n",
       " 'meterRanking___typename': nan,\n",
       " 'productionBudget_budget_amount': nan,\n",
       " 'productionBudget_budget_currency': nan,\n",
       " 'productionBudget_budget___typename': nan,\n",
       " 'productionBudget___typename': nan,\n",
       " 'lifetimeGross_total_amount': nan,\n",
       " 'lifetimeGross_total_currency': nan,\n",
       " 'lifetimeGross_total___typename': nan,\n",
       " 'lifetimeGross___typename': nan,\n",
       " 'openingWeekendGross_gross_total_amount': nan,\n",
       " 'openingWeekendGross_gross_total_currency': nan,\n",
       " 'openingWeekendGross_gross_total___typename': nan,\n",
       " 'openingWeekendGross_gross___typename': nan,\n",
       " 'openingWeekendGross_weekendEndDate': nan,\n",
       " 'openingWeekendGross___typename': nan,\n",
       " 'worldwideGross_total_amount': nan,\n",
       " 'worldwideGross_total_currency': nan,\n",
       " 'worldwideGross_total___typename': nan,\n",
       " 'worldwideGross___typename': nan,\n",
       " 'titleType_displayableProperty_value_plainText': nan,\n",
       " 'titleType_displayableProperty_value___typename': nan,\n",
       " 'titleType_displayableProperty___typename': nan,\n",
       " 'titleType_categories_0_value': nan,\n",
       " 'titleType_categories_0___typename': nan,\n",
       " 'titleType_canHaveEpisodes': nan,\n",
       " 'runtime_displayableProperty_value_plainText': nan,\n",
       " 'runtime_displayableProperty_value___typename': nan,\n",
       " 'runtime_displayableProperty___typename': nan}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(final_df.iloc[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
